{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-18T10:00:17.847327Z","iopub.status.busy":"2024-06-18T10:00:17.846683Z","iopub.status.idle":"2024-06-18T10:00:29.203724Z","shell.execute_reply":"2024-06-18T10:00:29.202799Z","shell.execute_reply.started":"2024-06-18T10:00:17.847294Z"},"trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import cv2\n","from torchvision.io import read_image\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, random_split, DataLoader, ConcatDataset\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:29.206202Z","iopub.status.busy":"2024-06-18T10:00:29.205850Z","iopub.status.idle":"2024-06-18T10:00:29.223612Z","shell.execute_reply":"2024-06-18T10:00:29.222489Z","shell.execute_reply.started":"2024-06-18T10:00:29.206172Z"},"trusted":true},"outputs":[],"source":["from torchvision.transforms import ToTensor\n","from PIL import Image\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision \n","from torchvision import transforms\n","from torchinfo import summary\n","import timm\n","class CustomImageDataset(Dataset):\n","    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n","        self.img_dir = img_dir\n","        self.label_dir = label_dir\n","        self.resize = resize\n","        self.transform = transform\n","        self.images = os.listdir(self.img_dir)\n","\n","    def __len__(self):\n","        return len(self.images)\n","    def read_mask(self, mask_path):\n","        image = cv2.imread(mask_path)\n","        image = cv2.resize(image, self.resize)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","        # lower boundary RED color range values; Hue (0 - 10)\n","        lower1 = np.array([0, 100, 20])\n","        upper1 = np.array([10, 255, 255])\n","        # upper boundary RED color range values; Hue (160 - 180)\n","        lower2 = np.array([160,100,20])\n","        upper2 = np.array([179,255,255])\n","        lower_mask = cv2.inRange(image, lower1, upper1)\n","        upper_mask = cv2.inRange(image, lower2, upper2)\n","        \n","        red_mask = lower_mask + upper_mask;\n","        red_mask[red_mask != 0] = 1\n","\n","        # boundary GREEN color range values; Hue (36 - 70)\n","        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n","        green_mask[green_mask != 0] = 2\n","\n","        full_mask = cv2.bitwise_or(red_mask, green_mask)\n","        full_mask = np.expand_dims(full_mask, axis=-1) \n","        full_mask = full_mask.astype(np.uint8)\n","        return full_mask\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        label_path = os.path.join(self.label_dir, self.images[idx])\n","        image = cv2.imread(img_path)  # Đọc ảnh dưới dạng BGR\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        label = self.read_mask(label_path)  # Đọc nhãn dưới dạng BGR\n","        image = cv2.resize(image, self.resize)\n","        if self.transform:\n","            transformed = self.transform(image=image, mask=label)\n","            image = transformed['image']\n","            label = transformed['mask']\n","        return image, label\n","    def show_image(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        label_path = os.path.join(self.label_dir, self.images[idx])\n","        image = plt.imread(img_path)\n","        label = plt.imread(label_path)\n","        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n","        axs[0].imshow(image)\n","        axs[0].set_title('Image')\n","        axs[1].imshow(label)\n","        axs[1].set_title('Label')\n","        plt.show()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:29.225462Z","iopub.status.busy":"2024-06-18T10:00:29.225117Z","iopub.status.idle":"2024-06-18T10:00:29.573653Z","shell.execute_reply":"2024-06-18T10:00:29.572518Z","shell.execute_reply.started":"2024-06-18T10:00:29.225434Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["image_path = []\n","TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n","for root, dirs, files in os.walk(TRAIN_DIR):\n","    for file in files:\n","        path = os.path.join(root,file)\n","        image_path.append(path)\n","mask_path = []\n","TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n","for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n","    for file in files:\n","        path = os.path.join(root,file)\n","        mask_path.append(path)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:30.033285Z","iopub.status.busy":"2024-06-18T10:00:30.032957Z","iopub.status.idle":"2024-06-18T10:00:30.040358Z","shell.execute_reply":"2024-06-18T10:00:30.038937Z","shell.execute_reply.started":"2024-06-18T10:00:30.033244Z"},"trusted":true},"outputs":[],"source":["trainsize = 352\n","batch_size = 8\n","\n","dataset = CustomImageDataset(img_dir= TRAIN_DIR,\n","                             label_dir= TRAIN_MASK_DIR,\n","                             resize= (trainsize,trainsize),\n","                             transform = None)\n","                             total_size = len(dataset)\n","train_size = int(total_size * 0.9)\n","valid_size = total_size - train_size\n","\n","# Split the dataset\n","train_dataset, val_dataset = random_split(dataset, [train_size, valid_size])"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T03:40:57.870107Z","iopub.status.busy":"2024-06-19T03:40:57.869400Z","iopub.status.idle":"2024-06-19T03:40:58.234417Z","shell.execute_reply":"2024-06-19T03:40:58.233303Z","shell.execute_reply.started":"2024-06-19T03:40:57.870078Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'CustomImageDataset' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomDataset\u001b[39;00m(\u001b[43mCustomImageDataset\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m dataset\n","\u001b[0;31mNameError\u001b[0m: name 'CustomImageDataset' is not defined"]}],"source":["class CustomDataset(CustomImageDataset):\n","    def __init__(self, dataset, transform=None):\n","        self.dataset = dataset\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        image, label = self.dataset[index] \n","        if self.transform:\n","            transformed = self.transform(image=image, mask=label)\n","            image = transformed['image']\n","            label = transformed['mask']\n","            label = label.permute(2,0,1)\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","train_transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    A.RandomGamma (gamma_limit=(70, 130), always_apply=False, p=0.2),\n","    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n","    A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()]),\n","    A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n","    A.RandomShadow(p=0.1),\n","    A.ShiftScaleRotate(p=0.45, border_mode=cv2.BORDER_CONSTANT, shift_limit=0.15, scale_limit=0.15),\n","    A.RandomCrop(384, 384),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    ToTensorV2(),\n","])\n","\n","val_transform = A.Compose([\n","    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n","    ToTensorV2(),\n","])\n","\n","train_dataset_not_aug = CustomDataset(train_dataset,\n","                             transform = val_transform)\n","train_dataset_aug = CustomDataset(train_dataset,\n","                             transform = train_transform)\n","val_dataset = CustomDataset(val_dataset,\n","                             transform = val_transform)\n","\n","train_dataset_new = ConcatDataset([train_dataset_not_aug, train_dataset_aug])\n","\n","train_loader = DataLoader(train_dataset_new, batch_size= batch_size, shuffle= True)\n","val_loader = DataLoader(val_dataset, batch_size= batch_size, shuffle= False)\n","print(len(train_dataset_new))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:30.631911Z","iopub.status.busy":"2024-06-18T10:00:30.631527Z","iopub.status.idle":"2024-06-18T10:00:30.648802Z","shell.execute_reply":"2024-06-18T10:00:30.647796Z","shell.execute_reply.started":"2024-06-18T10:00:30.631881Z"},"trusted":true},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, use_bottleneck=False):\n","        super(ConvBlock, self).__init__()\n","        if use_bottleneck:\n","            self.conv = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels * 2, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels * 2),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(out_channels * 2, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(inplace=True)\n","            )\n","        else:\n","            self.conv = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(inplace=True)\n","            )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class EncoderBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(EncoderBlock, self).__init__()\n","        self.conv_block = ConvBlock(in_channels, out_channels)\n","        self.pool = nn.MaxPool2d(2)\n","\n","    def forward(self, x):\n","        skip_connection = self.conv_block(x)\n","        downsampled = self.pool(skip_connection)\n","        return downsampled, skip_connection\n","\n","class DecoderBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, upsample_mode):\n","        super(DecoderBlock, self).__init__()\n","        if upsample_mode == 'conv_transpose':\n","            self.upsample = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n","        else:\n","            self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        \n","        self.conv_block = ConvBlock(in_channels, out_channels)\n","\n","    def forward(self, x, skip_connection):\n","        x = self.upsample(x)\n","        x = torch.cat([x, skip_connection], dim=1)\n","        return self.conv_block(x)\n","\n","class PolypSegmentationModel(nn.Module):\n","    def __init__(self, num_classes=3, upsample_mode='conv_transpose'):\n","        super(PolypSegmentationModel, self).__init__()\n","        self.num_classes = num_classes\n","        self.encoder = timm.create_model(\"resnet152\", pretrained=True, features_only=True)\n","        \n","        self.encoder_block1 = EncoderBlock(64, 128)\n","        self.encoder_block2 = EncoderBlock(256, 512)\n","        self.encoder_block3 = EncoderBlock(512, 1024)\n","        self.encoder_block4 = EncoderBlock(1024, 2048)\n","        \n","        self.bottleneck = ConvBlock(2048, 1024)\n","        \n","        self.decoder_block1 = DecoderBlock(2048, 512, upsample_mode)\n","        self.decoder_block2 = DecoderBlock(1024, 256, upsample_mode)\n","        self.decoder_block3 = DecoderBlock(512, 128, upsample_mode)\n","        self.decoder_block4 = DecoderBlock(256, 64, upsample_mode)\n","        \n","        self.final_conv = nn.Conv2d(128, num_classes, kernel_size=1)\n","        self.final_upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n","\n","    def forward(self, x):\n","        encoder_outputs = self.encoder(x)\n","        x1, x2, x3, x4, x5 = encoder_outputs\n","\n","        x = self.bottleneck(x5)\n","        x = self.decoder_block1(x, x4)\n","        x = self.decoder_block2(x, x3)\n","        x = self.decoder_block3(x, x2)\n","        x = self.decoder_block4(x, x1)\n","\n","        x = self.final_conv(x)\n","        x = self.final_upsample(x)\n","        return x"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:30.666697Z","iopub.status.busy":"2024-06-18T10:00:30.666365Z","iopub.status.idle":"2024-06-18T10:00:30.677140Z","shell.execute_reply":"2024-06-18T10:00:30.676275Z","shell.execute_reply.started":"2024-06-18T10:00:30.666670Z"},"trusted":true},"outputs":[],"source":["color_dict= {0: (0, 0, 0),\n","             1: (255, 0, 0),\n","             2: (0, 255, 0)}\n","def mask_to_rgb(mask, color_dict):\n","    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n","#     print(output.shape)\n","    for k in color_dict.keys():\n","        output[mask==k] = color_dict[k]\n","\n","    return np.uint8(output)    "]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:30.678596Z","iopub.status.busy":"2024-06-18T10:00:30.678309Z","iopub.status.idle":"2024-06-18T10:00:35.106016Z","shell.execute_reply":"2024-06-18T10:00:35.105140Z","shell.execute_reply.started":"2024-06-18T10:00:30.678572Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"028420e9bafe44dfbd64f8ef8c4a2e56","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["torch.cuda.empty_cache()\n","model = PolypModel(3)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:35.108052Z","iopub.status.busy":"2024-06-18T10:00:35.107592Z","iopub.status.idle":"2024-06-18T10:00:35.116845Z","shell.execute_reply":"2024-06-18T10:00:35.115808Z","shell.execute_reply.started":"2024-06-18T10:00:35.108018Z"},"trusted":true},"outputs":[],"source":["learning_rate = 0.0001\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:35.118463Z","iopub.status.busy":"2024-06-18T10:00:35.118092Z","iopub.status.idle":"2024-06-18T10:00:54.109142Z","shell.execute_reply":"2024-06-18T10:00:54.107784Z","shell.execute_reply.started":"2024-06-18T10:00:35.118419Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.0)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\n","Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n","Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.3.1)\n","Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\n","Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!pip install wandb\n","!wandb login 'cc8ac86b9aed43b8c570f6a4cceca495499e73f7'"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:54.111098Z","iopub.status.busy":"2024-06-18T10:00:54.110745Z","iopub.status.idle":"2024-06-18T10:00:56.357218Z","shell.execute_reply":"2024-06-18T10:00:56.356163Z","shell.execute_reply.started":"2024-06-18T10:00:54.111066Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoanghaiphongngu2\u001b[0m (\u001b[33mhustt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:00:56.358793Z","iopub.status.busy":"2024-06-18T10:00:56.358328Z","iopub.status.idle":"2024-06-18T10:01:13.233661Z","shell.execute_reply":"2024-06-18T10:01:13.232521Z","shell.execute_reply.started":"2024-06-18T10:00:56.358765Z"},"trusted":true},"outputs":[{"data":{"text/html":["wandb version 0.17.2 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240618_100056-vgn3a9od</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/hustt/Polyp/runs/vgn3a9od' target=\"_blank\">feasible-plasma-4</a></strong> to <a href='https://wandb.ai/hustt/Polyp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/hustt/Polyp' target=\"_blank\">https://wandb.ai/hustt/Polyp</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/hustt/Polyp/runs/vgn3a9od' target=\"_blank\">https://wandb.ai/hustt/Polyp/runs/vgn3a9od</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hustt/Polyp/runs/vgn3a9od?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x79b4b3ac4490>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(\n","    project = 'Polyp',\n","    config = {\n","        'learning_rate': 0.0001,\n","        'architecture': 'Unet',\n","        'dataset': 'Polyp',\n","        'epoch': 200\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-18T10:01:13.235381Z","iopub.status.busy":"2024-06-18T10:01:13.234993Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/200], val_loss: 0.2002771566\n","SAVE +1\n","Epoch [2/200], val_loss: 0.1171527837\n","SAVE +1\n","Epoch [3/200], val_loss: 0.0848681732\n","SAVE +1\n","Epoch [4/200], val_loss: 0.0728300231\n","SAVE +1\n","Epoch [5/200], val_loss: 0.0582184274\n","SAVE +1\n","Epoch [6/200], val_loss: 0.0735967138\n","Epoch [7/200], val_loss: 0.0495599097\n","SAVE +1\n","Epoch [8/200], val_loss: 0.0432764006\n","SAVE +1\n","Epoch [9/200], val_loss: 0.0508028328\n","Epoch [10/200], val_loss: 0.0395696165\n","SAVE +1\n","Epoch [11/200], val_loss: 0.0480875465\n","Epoch [12/200], val_loss: 0.0552731057\n","Epoch [13/200], val_loss: 0.0446315535\n","Epoch [14/200], val_loss: 0.0374848564\n","SAVE +1\n","Epoch [15/200], val_loss: 0.0412464636\n","Epoch [16/200], val_loss: 0.0420085890\n","Epoch [17/200], val_loss: 0.0558841385\n","Epoch [18/200], val_loss: 0.0353916963\n","SAVE +1\n","Epoch [19/200], val_loss: 0.0329898317\n","SAVE +1\n","Epoch [20/200], val_loss: 0.0371768039\n","Epoch [21/200], val_loss: 0.0387581135\n","Epoch [22/200], val_loss: 0.0353940721\n","Epoch [23/200], val_loss: 0.0421724975\n","Epoch [24/200], val_loss: 0.0406543237\n","Epoch [25/200], val_loss: 0.0348399552\n","Epoch [26/200], val_loss: 0.0337635582\n","Epoch [27/200], val_loss: 0.0373127841\n","Epoch [28/200], val_loss: 0.0294044925\n","SAVE +1\n","Epoch [29/200], val_loss: 0.0408173004\n","Epoch [30/200], val_loss: 0.0314320345\n","Epoch [31/200], val_loss: 0.0357311960\n","Epoch [32/200], val_loss: 0.0341523680\n","Epoch [33/200], val_loss: 0.0277115883\n","SAVE +1\n","Epoch [34/200], val_loss: 0.0326835565\n","Epoch [35/200], val_loss: 0.0285216591\n","Epoch [36/200], val_loss: 0.0414424346\n","Epoch [37/200], val_loss: 0.0490003173\n","Epoch [38/200], val_loss: 0.0437055871\n","Epoch [39/200], val_loss: 0.0322285341\n","Epoch [40/200], val_loss: 0.0402719664\n","Epoch [41/200], val_loss: 0.0437290926\n","Epoch [42/200], val_loss: 0.0314899410\n","Epoch [43/200], val_loss: 0.0332007298\n","Epoch [44/200], val_loss: 0.0382982428\n","Epoch [45/200], val_loss: 0.0378979505\n","Epoch [46/200], val_loss: 0.0354684453\n","Epoch [47/200], val_loss: 0.0394595962\n","Epoch [48/200], val_loss: 0.0412837162\n","Epoch [49/200], val_loss: 0.0383683898\n","Epoch [50/200], val_loss: 0.0383749574\n","Epoch [51/200], val_loss: 0.0463138166\n","Epoch [52/200], val_loss: 0.0474710829\n","Epoch [53/200], val_loss: 0.0399975300\n","Epoch [54/200], val_loss: 0.0397970995\n","Epoch [55/200], val_loss: 0.0385943524\n","Epoch [56/200], val_loss: 0.0382244933\n","Epoch [57/200], val_loss: 0.0332337543\n","Epoch [58/200], val_loss: 0.0274494382\n","SAVE +1\n","Epoch [59/200], val_loss: 0.0281901633\n","Epoch [60/200], val_loss: 0.0211761435\n","SAVE +1\n","Epoch [61/200], val_loss: 0.0274476971\n","Epoch [62/200], val_loss: 0.0380876199\n","Epoch [63/200], val_loss: 0.0351586206\n","Epoch [64/200], val_loss: 0.0414013226\n","Epoch [65/200], val_loss: 0.0370340431\n","Epoch [66/200], val_loss: 0.0366288704\n","Epoch [67/200], val_loss: 0.0408430478\n","Epoch [68/200], val_loss: 0.0420620929\n","Epoch [69/200], val_loss: 0.0544499380\n","Epoch [70/200], val_loss: 0.0337487472\n","Epoch [71/200], val_loss: 0.0396952397\n","Epoch [72/200], val_loss: 0.0459656486\n","Epoch [73/200], val_loss: 0.0359227022\n","Epoch [74/200], val_loss: 0.0376474174\n","Epoch [75/200], val_loss: 0.0375605180\n","Epoch [76/200], val_loss: 0.0317789975\n","Epoch [77/200], val_loss: 0.0395514803\n","Epoch [78/200], val_loss: 0.0308275792\n","Epoch [79/200], val_loss: 0.0392850973\n","Epoch [80/200], val_loss: 0.0362815916\n","Epoch [81/200], val_loss: 0.0402032044\n","Epoch [82/200], val_loss: 0.0389524494\n","Epoch [83/200], val_loss: 0.0485320679\n","Epoch [84/200], val_loss: 0.0461357232\n","Epoch [85/200], val_loss: 0.0412172699\n","Epoch [86/200], val_loss: 0.0369184761\n","Epoch [87/200], val_loss: 0.0392848756\n","Epoch [88/200], val_loss: 0.0375429571\n","Epoch [89/200], val_loss: 0.0502607302\n","Epoch [90/200], val_loss: 0.0342435032\n","Epoch [91/200], val_loss: 0.0397823410\n","Epoch [92/200], val_loss: 0.0381207359\n","Epoch [93/200], val_loss: 0.0278564536\n","Epoch [94/200], val_loss: 0.0351577311\n","Epoch [95/200], val_loss: 0.0407662670\n","Epoch [96/200], val_loss: 0.0354668902\n","Epoch [97/200], val_loss: 0.0430146689\n","Epoch [98/200], val_loss: 0.0492784960\n","Epoch [99/200], val_loss: 0.0367157405\n","Epoch [100/200], val_loss: 0.0413760589\n","Epoch [101/200], val_loss: 0.0333057492\n","Epoch [102/200], val_loss: 0.0351383340\n","Epoch [103/200], val_loss: 0.0339285760\n","Epoch [104/200], val_loss: 0.0406049944\n","Epoch [105/200], val_loss: 0.0383887464\n","Epoch [106/200], val_loss: 0.0459247744\n","Epoch [107/200], val_loss: 0.0384874944\n","Epoch [108/200], val_loss: 0.0419603155\n","Epoch [109/200], val_loss: 0.0439383221\n","Epoch [110/200], val_loss: 0.0459269450\n","Epoch [111/200], val_loss: 0.0461502223\n","Epoch [112/200], val_loss: 0.0512776495\n","Epoch [113/200], val_loss: 0.0444307809\n","Epoch [114/200], val_loss: 0.0450335593\n","Epoch [115/200], val_loss: 0.0408574236\n","Epoch [116/200], val_loss: 0.0404954513\n","Epoch [117/200], val_loss: 0.0449365840\n","Epoch [118/200], val_loss: 0.0413044676\n","Epoch [119/200], val_loss: 0.0435758130\n","Epoch [120/200], val_loss: 0.0458696458\n","Epoch [121/200], val_loss: 0.0456252541\n","Epoch [122/200], val_loss: 0.0376131477\n","Epoch [123/200], val_loss: 0.0501949458\n","Epoch [124/200], val_loss: 0.0344735423\n","Epoch [125/200], val_loss: 0.0404728484\n","Epoch [126/200], val_loss: 0.0406246185\n","Epoch [127/200], val_loss: 0.0472013849\n","Epoch [128/200], val_loss: 0.0462303361\n","Epoch [129/200], val_loss: 0.0478446646\n","Epoch [130/200], val_loss: 0.0483512353\n","Epoch [131/200], val_loss: 0.0452674502\n","Epoch [132/200], val_loss: 0.0507491401\n","Epoch [133/200], val_loss: 0.0431349049\n","Epoch [134/200], val_loss: 0.0481229390\n","Epoch [135/200], val_loss: 0.0394208414\n","Epoch [136/200], val_loss: 0.0423706502\n","Epoch [137/200], val_loss: 0.0454110716\n","Epoch [138/200], val_loss: 0.0337736805\n","Epoch [139/200], val_loss: 0.0489215907\n","Epoch [140/200], val_loss: 0.0412080556\n","Epoch [141/200], val_loss: 0.0378356719\n","Epoch [142/200], val_loss: 0.0509765336\n","Epoch [143/200], val_loss: 0.0440006646\n","Epoch [144/200], val_loss: 0.0432848675\n","Epoch [145/200], val_loss: 0.0402291291\n","Epoch [146/200], val_loss: 0.0468707622\n","Epoch [147/200], val_loss: 0.0449348245\n","Epoch [148/200], val_loss: 0.0474861273\n","Epoch [149/200], val_loss: 0.0638774844\n","Epoch [150/200], val_loss: 0.0559192145\n","Epoch [151/200], val_loss: 0.0498173181\n","Epoch [152/200], val_loss: 0.0339281321\n","Epoch [153/200], val_loss: 0.0371327153\n","Epoch [154/200], val_loss: 0.0401667696\n","Epoch [155/200], val_loss: 0.0347034705\n","Epoch [156/200], val_loss: 0.0389080512\n","Epoch [157/200], val_loss: 0.0453753047\n","Epoch [158/200], val_loss: 0.0513544021\n","Epoch [159/200], val_loss: 0.0387283887\n","Epoch [160/200], val_loss: 0.0432696309\n","Epoch [161/200], val_loss: 0.0414796043\n","Epoch [162/200], val_loss: 0.0492709317\n","Epoch [163/200], val_loss: 0.0403174340\n","Epoch [164/200], val_loss: 0.0447802882\n"]}],"source":["# Set the number of training epochs\n","num_epochs = 200\n","\n","# Move the model to the device (e.g., GPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","train_loss_array = []\n","val_loss_array = []\n","best_val_loss = 999\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # Forward pass\n","        labels = labels.squeeze(dim=1).long()\n","\n","        outputs = model(images)\n","\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        total_loss += loss.item()  # Accumulate the loss\n","    train_loss_epoch = total_loss / len(train_loader)\n","\n","        \n","# Perform validation\n","    model.eval()\n","    with torch.no_grad():\n","        val_loss = 0\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            labels = labels.squeeze(dim=1).long()\n","\n","            # Forward pass\n","            outputs = model(images)\n","            val_loss += criterion(outputs.float(),labels.long()).item()\n","    val_loss_epoch = val_loss/len(val_loader)\n","    # Print the loss of valid_dataset for this epoch\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], val_loss: {val_loss/len(val_loader):.10f}\")\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        checkpoint = { \n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","        }\n","        save_path = f'checkpoint_final.pth'\n","        torch.save(checkpoint, save_path)\n","        print('SAVE +1')\n","    # Calculate average loss for the epoch\n","    \n","    wandb.log({'Val_loss': val_loss_epoch,\n","               'Train_loss': train_loss_epoch\n","              })\n","    train_loss_array.append(train_loss_epoch)\n","    val_loss_array.append(val_loss_epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":2715462,"sourceId":30892,"sourceType":"competition"}],"dockerImageVersionId":30716,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
